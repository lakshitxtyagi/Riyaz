{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ---------------------- Parameters ----------------------\n",
    "n_mfcc = 40\n",
    "max_pad_len = 174\n",
    "\n",
    "# ---------------------- Feature Extraction ----------------------\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "        if mfccs.shape[1] < max_pad_len:\n",
    "            pad_width = max_pad_len - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfccs = mfccs[:, :max_pad_len]\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error extracting features from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ---------------------- Load and Split Data ----------------------\n",
    "def load_and_split_data(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    print(f\"\\nðŸ“‚ Loading data from: {folder_path}\")\n",
    "    \n",
    "    for label in os.listdir(folder_path):\n",
    "        class_folder = os.path.join(folder_path, label)\n",
    "        if os.path.isdir(class_folder):\n",
    "            clean_label = re.sub(r'\\s*Test.*$', '', label).strip()\n",
    "            for filename in os.listdir(class_folder):\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(class_folder, filename)\n",
    "                    mfcc = extract_features(file_path)\n",
    "                    if mfcc is not None:\n",
    "                        X.append(mfcc)\n",
    "                        y.append(clean_label)\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(X)} audio files from {folder_path}\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Normalize features\n",
    "    X = (X - np.mean(X)) / np.std(X)\n",
    "\n",
    "    # Reshape for LSTM\n",
    "    X = X.transpose((0, 2, 1))  # (samples, timesteps, features)\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_enc = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Train-Val-Test split (60/20/20)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y_enc, test_size=0.4, stratify=y_enc, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, label_encoder\n",
    "\n",
    "# ---------------------- Build Model ----------------------\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ---------------------- Train and Evaluate ----------------------\n",
    "def train_model(dataset_folder):\n",
    "    print(\"ðŸ“¦ Loading and splitting data...\")\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = load_and_split_data(dataset_folder)\n",
    "\n",
    "    model = build_model(input_shape=X_train.shape[1:], num_classes=len(label_encoder.classes_))\n",
    "    \n",
    "    print(\"\\nðŸš€ Starting training...\")\n",
    "    model.fit(X_train, y_train, epochs=40, batch_size=16, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\nðŸ“Š Evaluating on test data...\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nâœ… Final test accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ---------------------- Run ----------------------\n",
    "dataset_folder = r\"C:\\Users\\Lakshay Aggarwal\\Downloads\\LSTM-20250508T035831Z-1-001\\LSTM\\dataset\"\n",
    "model = train_model(dataset_folder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
